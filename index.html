<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="From Master to Agent, Bridging Generations by the Intelligent Legacy: How Lightweight LLM Standardize the Preserving and scaling of the Medical Expertise of human Doctors - Chanyong Luo et al.">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="Chanyong Luo, Jirui Dai">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="From Master to Agent, Bridging Generations by the Intelligent Legacy: How Lightweight LLM Standardize the Preserving and scaling of the Medical Expertise of human Doctors">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="From Master to Agent, Bridging Generations by the Intelligent Legacy: How Lightweight LLM Standardize the Preserving and scaling of the Medical Expertise of human Doctors - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="Chanyong Luo">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="From Master to Agent, Bridging Generations by the Intelligent Legacy: How Lightweight LLM Standardize the Preserving and scaling of the Medical Expertise of human Doctors">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="From Master to Agent, Bridging Generations by the Intelligent Legacy: How Lightweight LLM Standardize the Preserving and scaling of the Medical Expertise of human Doctors - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="From Master to Agent, Bridging Generations by the Intelligent Legacy: How Lightweight LLM Standardize the Preserving and scaling of the Medical Expertise of human Doctors">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>From Master to Agent, Bridging Generations by the Intelligent Legacy: How Lightweight LLM Standardize the Preserving and scaling of the Medical Expertise of human Doctors - Chanyong Luo et al. | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "From Master to Agent, Bridging Generations by the Intelligent Legacy: How Lightweight LLM Standardize the Preserving and scaling of the Medical Expertise of human Doctors",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "Chanyong Luo",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "Jirui Dai",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>

<body>

  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <!-- TODO: Replace with your lab's related works -->
        <a href="https://arxiv.org/abs/PAPER_ID_1" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 1</h5>
            <!-- TODO: Replace with brief description -->
            <p>Brief description of the work and its main contribution.</p>
            <!-- TODO: Replace with venue and year -->
            <span class="work-venue">Conference/Journal 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <!-- TODO: Add more related works or remove extra items -->
        <a href="https://arxiv.org/abs/PAPER_ID_2" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 2</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/PAPER_ID_3" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Paper Title 3</h5>
            <p>Brief description of the work and its main contribution.</p>
            <span class="work-venue">Conference/Journal 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div>

  <main id="main-content">

    <!-- HERO -->
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <!-- TODO: Replace with your paper title -->
              <h1 class="title is-1 publication-title">From Master to Agent, Bridging Generations by the Intelligent Legacy: How Lightweight LLM Standardize the Preserving and scaling of the Medical Expertise of human Doctors</h1>
              <div class="is-size-5 publication-authors">
  <span class="author-block">
    Chanyong Luo<sup>3</sup>,
  </span>
  <span class="author-block">
    Jirui Dai<sup>5,a</sup>,
  </span>
  <span class="author-block">
    Zhendong Wang<sup>4,a</sup>,
  </span>
  <span class="author-block">
    Jing Wang<sup>7</sup>,
  </span>
  <span class="author-block">
    Kuichen<sup>10</sup>,
  </span>
  <span class="author-block">
    Jiaxi Yang<sup>9</sup>,
  </span>
  <span class="author-block">
    Bingjie Lu<sup>11</sup>,
  </span>
  <span class="author-block">
    Jiaxin Hao<sup>6</sup>,
  </span>
  <span class="author-block">
    Bing Li<sup>6</sup>,
  </span>
  <span class="author-block">
    Ruiyang He<sup>6</sup>,
  </span>
  <span class="author-block">
    Yiyu Qiao<sup>6</sup>,
  </span>
  <span class="author-block">
    Chenkai Zhang<sup>8</sup>,
  </span>
  <span class="author-block">
    Kaiyu Wang<sup>8</sup>,
  </span>
  <span class="author-block">
    Zhi Liu<sup>2,&#9993;</sup>,
  </span>
  <span class="author-block">
    Zeyu Zheng<sup>8,&#9993;</sup>,
  </span>
  <span class="author-block">
    Yan Li<sup>6,&#9993;</sup>,
  </span>
  <span class="author-block">
    Xiaohong Gu<sup>1</sup>
  </span>
</div>

                  <div class="is-size-5 publication-authors">
  <span class="author-block">
    1.the School of Chinese Medicine, the Beijing University of Chinese Medicine, Beijing, China<br>
    2.the School of Pharmacy, Nanjing University of Chinese Medicine, Nanjing, China<br>
    3.the Infectious disease department, Dongfang Hospital, Beijing University of Chinese Medicine, Beijing, China<br>
    4.the Gulou Hospital of Traditional Chinese Medicine of Beijing，Beijing, China<br>
    5.the Department of Computer Science, Johns Hopkins University, Baltimore, USA<br>
    6.the Department of Education, Dongzhimen Hospital, Beijing University of Chinese Medicine, Beijing, China<br>
    7.the Department of Pediatrics, Wangjing Hospital, China Academy of Chinese Medical Sciences, Beijing, China<br>
    8.the School of Information Engineering, Huzhou University‌, Huzhou, China<br>
    9.Research Center for Scientific Data Hub, Zhejiang Lab, Hangzhou, China<br>
    10.the Frontier Basic Research Center, Zhejiang Lab, Hangzhou, China<br>
    11.the Research Center for High Efficiency Computing Infrastructure, Zhejiang Lab, Hangzhou, China
  </span>
</div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- TODO: Replace with your GitHub repository URL -->
                    <span class="link-block">
                      <a href="https://github.com/YOUR REPO HERE" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- TODO: Update with your arXiv paper ID -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <!-- TODO: Replace with your dataset link (e.g., Hugging Face) -->
                  <span class="link-block">
                    <a href="https://huggingface.co/datasets/YOUR DATASET HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-database"></i>
                    </span>
                    <span>Dataset</span>
                  </a>
                </span>

              </div>
            </div>

          </div>
        </div>
      </div>
    </section>

    <!-- TEASER (可以自己换图) -->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <figure class="image">
            <img src="static/images/teaser.png"
                 alt="High-level illustration of the main idea"
                 loading="lazy">
          </figure>
          <h2 class="subtitle has-text-centered" style="margin-top:1.5rem;">
            Brief one/sentence teaser describing your key idea and what the figure shows.
          </h2>
        </div>
      </div>
    </section>

    <!-- ABSTRACT -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <!-- TODO: Replace with your paper abstract -->
          <p>
            Medicine is fundamentally an empirical body of knowledge accumulated through long-term observation, validation, and refinement, and ultimately realized in the messy, high-variance real clinical practice. Physicians’ diagnostic-and-therapeutic competence is gradually forged through repeated cycles of “application–reflection–improvement,” crystallizing into distinctive, individualized methodologies. Considering the fact of the substantial variation in treatment outcomes, the formation of master physicians’ knowledge systems is necessary but time-consuming and their transmission is often limited in scope, making high-quality expertise difficult to scale and disseminate, and the scarcity of advanced clinical resources. To mitigate these challenges, we propose Med-Shicheng, a general framework that enables large language model to systematically learn and transfer distinguished physicians’ diagnostic-and-therapeutic philosophy, and case-dependent adaptation rules in a standardized manner. Built upon Tianyi, Med-Shicheng comprises five elaborately designed five stages. We take five National Masters of Chinese Medicine/distinguished TCM physicians as representative targets, curate and organize multi-source materials and train a single model to simultaneously internalize the five distinctive knowledge systems across seven tasks: etiology–pathogenesis analysis, syndrome diagnosis, determination of treatment principles, prescription generation, prescription explanation, symptom evolution with corresponding regimen modifications, and clinical advice. Implemented on Qwen2.5-1.5B-Base, Med-Shicheng can be deployed on resource-constrained GPUs, while demonstrating evaluation performance comparable to DeepSeek-R1 and GPT-5. Besides, we further analyze the reliability of LLM-as-a-Judge against physician-based assessment. It shows that although automated judging captures broad performance trends, it exhibits noticeable biases in fine-grained, individualized clinical distinctions, indicating that physician involvement remains necessary when ground truth is unavailable and that judge models require targeted medical domain adaptation to achieve reliable evaluation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Main content sections -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Med-Schiehng TCM heritage Framework</h2>
    <div class="columns is-vcentered">
      <div class="column is-half">
        <figure class="image">
          <img src="static/images/section1.png"
               alt="Med-Schiehng TCM heritage Framework illustration"
               loading="lazy">
        </figure>
      </div>
      <div class="column is-half">
        <div class="content has-text-justified">
          <p>
            In this work, we proposed a general paradigm to enable the LLM learning the outstanding medical knowledge system and D&amp;T experience of the distinctive TCM doctors, named Med-Shicheng. It consists of five stages to ensure a general-purpose LLM into a medical domain LLM that can master the D&amp;T knowledge and strategies of different distinctive TCM doctors: (1) Medical in-domain foundation model construction, (2) TCM regular D&amp;T strategy learning, (3) Reasoning-based D&amp;T reinforced fine-tuning, (4) Unique medical knowledge fine-tuning, and (5) Reasoning-based unique D&amp;T strategy reinforced learning. In each stage, we design and construct a dataset according to the TCM domain tasks and logic. To evaluate the model’s performance trained by Med-Shicheng, we also design an evaluation framework to evaluate all comparison models from four dimensions: diagnostic accuracy, reasoning quality, extent of expert alignment, and knowledge recall.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Evaluatino Benchmark</h2>
    <div class="columns is-vcentered">
      <div class="column is-half">
        <div class="content has-text-justified">
          <p>
            The evaluation Framework. It contains two types of evaluations: automatic evaluation and Human doctor evaluations. For the automatic evaluation, we take the state-of-the-art LLMs with universal complex problem solving abilities such as Deepseek and GPT as the judge to evaluate all comparison models’ prediction on test samples. In this study, we take both deepseek-V3.2 and GPT-5 as the judges which means each model generated response will be evaluated twice. Deepseek-V3.2 and GPT-5 assess if the responses generated from all comparison models are desirable for the query by their own and considering the golden label at the meantime. The reason we choose this evaluation method is that the response to the tasks in this study is a long text over the test clinical case which contains seven essential parts with professional description to express the same meaning, so does the label. It’s impossible to evaluate them by the classic evaluation metrics, such as accuracy, recall, and F1-score. The higher score model obtained, the better performance of the corresponding model. For the human doctor evaluation, we invited 18 experienced TCM doctors with senior title, and divide them into five groups of TCM doctors for these five targeted distinguished TCM doctor, all of whom are the apprentices or students in each group. We employed the Delphi method to establish TCM expert consensus standards, offering the invited TCM doctors a unified evaluation principles and requirements to evaluate all comparison models from five dimensions: (1) the D&amp;T similarity to target distinguished TCM doctors, (2) the consistency with TCM philosophical framework, (3) the safety compliance, (4) therapeutic completeness, and (5) clinical coherence. Detailed information regarding the criteria used for expert human evaluation can be found in Appendix B of the paper.
          </p>
        </div>
      </div>
      <div class="column is-half">
        <figure class="image">
          <img src="static/images/section2.png"
               alt="Evaluatino Benchmark illustration"
               loading="lazy">
        </figure>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Automatic Evaluations</h2>
    <div class="columns is-vcentered">
      <div class="column is-half">
        <figure class="image">
          <img src="static/images/section3.png"
               alt="Automatic Evaluations illustration"
               loading="lazy">
        </figure>
      </div>
      <div class="column is-half">
        <div class="content has-text-justified">
          <p>
            The automatic evaluation results judged by Deepseek-V3.2 and GPT-5, which are illustrated in subfigure a. and b. respectively. In general, the evaluation results by Deepseek-V3.2 and GPT-5 shows the consistent trend for all model’s prediction on all test samples of target distinguished TCM doctors except for the scores for HuatuoGPT2-7B on doctor Huaitang Du’s test samples which obtains the highest TCM prescription and treatment principle results. By reviewing HuatuoGPT2-7B&#x27;s geneartion on Dr. Huaitang Du’s test samples, we noticed that it achieved exceptionally high scores in TCM prescription and treatment principles by generating content identical to the labels in half of the cases, while differing significantly in other items. This anomaly suggests that these specific samples may have been part of HuatuoGPT2-7B’s training data. For total scores, the comparison models can be divided into two distinct groups: (1) the higher performance models: Med-Shicheng, GPT-5, Deepseek-R1, Qwen3-235B-A22B-Thinking, Gemini-2.5-pro; and (2) the lower performance models: Qwen2.5-1.5B-Instruct, Tianyi, Huatuo-GPT2. The Med-Shicheng is the only model, which has the least parameters, that can generate the comparable quality content to the models with hundreds of billions of parameters. However, there is no model that can obtain the consistently highest scores on all target doctor’s test samples. Taking the results of Deepseek-V3.2 as an example, with the largest model scales, Deepseek and GPT-5 obtain the top 2 scores in most items of most cases, while Med-shicheng, Gemini-2.5-pro, and Qwen3-235B-A22B-Thinking also show their desirable performance than Deepseek and GPT-5, such as in the case of Fengchun Wang, Shaoqin Zhao, and Huaitang Du. The scores judged by GPT-5 also confirm these trends with the larger evaluation values than Deepseek. All scores are the average scores across all test samples.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Human Doctors Evaluations</h2>
    <div class="columns is-vcentered">
      <div class="column is-half">
        <div class="content has-text-justified">
          <p>
            The human doctor evaluations for all target distinguished TCM doctors. All scores of comparison models are grouped by doctors. The weighted total scores that are grouped by models are displayed separately in a sub-figure. For the clearness, we named all comparison models’ name with the numbers from 1 to 8, and their names are placed at the bottom of the figure. All target distinguished doctors’ cases evaluations are grouped by model, and each of the evaluation dimension are presented in a sub-figure. Overall, human doctors tend to offer the different rating distributions compared to GPT-5 and Deepseek-V3.2. Human doctors prefer score Med-shicheng with higher scores for most target TCM doctors’ cases in almost all 5 dimensions while for results presented in Fig.3 GPT-5 and Deepseek-V3.2 are not. For instance, Med-shicheng obtains the scores comparable to the top or even the top scores in the cases of HuaiTang Du, Xiaohong Gu, Fengchun Wang, and Bowei Qin on dimension of similarity to distinguished physicians with the small variances. However, in Section. 3., the GPT-5 and Deepseek-V3.2 merely rate Med-shicheng with top scores. This pheromone may propose that the LLMs with extremely large parameters scale (e.g., GPT or Deepseek) are capable of evaluating the complicated and long content generated by specialized trained in-domain LLMs under the elaborately designed instructions. Yet, such ability is limited when the evaluation requirements are becoming more specific and professional. In this work, the LLMs are required to assess if the comparison models can generate the response along with the target doctor’s habits in TCM diagnosis, treatment principles, medication. They only assess these contents with the ordinary TCM knowledge and provide the scores even though for the cases of Huaitang Du whose books and resources are widely accessible. While, human TCM doctors can differentiate the differences of doctor’s specialized TCM system and the normal TCM knowledge presented in models’ responses. Such evaluation weakness of GPT and Deepseek is more obvious in the scores of Bowei Qin, human doctors rated Med-shicheng at the second place in almost 5 dimensions in cases of Bowei Qin while GPT and Deepseek rated it at the fourth place. The similar evaluation differences occur in the cases of HuaiTang Du and Xiaohong Gu.
          </p>
        </div>
      </div>
      <div class="column is-half">
        <figure class="image">
          <img src="static/images/section4.png"
               alt="Human Doctors Evaluations illustration"
               loading="lazy">
        </figure>
      </div>
    </div>
  </div>
</section>

<!-- End main content sections -->

<!-- BibTeX citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={Your Paper Title Here},
  author={First Author and Second Author and Third Author},
  journal={Conference/Journal Name},
  year={2024},
  url={https://your-domain.com/your-project-page}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>
            which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer.
            <br>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
